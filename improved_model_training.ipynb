{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Churn Prediction Model\n",
    "\n",
    "This notebook implements several improvements to the churn prediction model:\n",
    "1. Advanced data preprocessing\n",
    "2. Feature engineering\n",
    "3. Multiple model comparison\n",
    "4. Hyperparameter tuning\n",
    "5. Handling class imbalance\n",
    "6. Comprehensive model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for TotalCharges issues\n",
    "print(f\"TotalCharges unique values count: {df['TotalCharges'].nunique()}\")\n",
    "print(f\"TotalCharges sample: {df['TotalCharges'].sample(5).values}\")\n",
    "\n",
    "# Convert TotalCharges to numeric\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "print(f\"\\nMissing values after conversion: {df['TotalCharges'].isnull().sum()}\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nChurn distribution:\")\n",
    "churn_counts = df['Churn'].value_counts(normalize=True) * 100\n",
    "print(churn_counts)\n",
    "\n",
    "# Visualize churn distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Churn', data=df)\n",
    "plt.title('Churn Distribution')\n",
    "plt.ylabel('Count')\n",
    "for i, count in enumerate(df['Churn'].value_counts()):\n",
    "    plt.text(i, count + 100, f\"{count} ({count/len(df):.1%})\", ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Drop customerID as it's not relevant for prediction\n",
    "df = df.drop('customerID', axis=1)\n",
    "\n",
    "# Fill missing values in TotalCharges with the median\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "# 1. Create tenure-related features\n",
    "df['tenure_group'] = pd.qcut(df['tenure'], 4, labels=['0-1 year', '1-3 years', '3-5 years', '5+ years'])\n",
    "\n",
    "# 2. Create average monthly charge\n",
    "df['avg_monthly_charges'] = df['TotalCharges'] / (df['tenure'] + 0.1)  # Adding 0.1 to avoid division by zero\n",
    "\n",
    "# 3. Create charge difference (how much more/less than average)\n",
    "df['charge_diff'] = df['MonthlyCharges'] - df['avg_monthly_charges']\n",
    "\n",
    "# 4. Create service count feature\n",
    "service_columns = ['PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', \n",
    "                   'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "\n",
    "# Function to count services\n",
    "def count_services(row):\n",
    "    count = 0\n",
    "    for col in service_columns:\n",
    "        if row[col] not in ['No', 'No phone service', 'No internet service', 'DSL']:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "df['service_count'] = df.apply(count_services, axis=1)\n",
    "\n",
    "# 5. Create binary flags for premium services\n",
    "df['has_premium_tech'] = df['TechSupport'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "df['has_premium_security'] = df['OnlineSecurity'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "df['has_premium_support'] = df[['OnlineBackup', 'DeviceProtection']].apply(\n",
    "    lambda x: 1 if 'Yes' in x.values else 0, axis=1\n",
    ")\n",
    "df['has_streaming'] = df[['StreamingTV', 'StreamingMovies']].apply(\n",
    "    lambda x: 1 if 'Yes' in x.values else 0, axis=1\n",
    ")\n",
    "\n",
    "# 6. Create interaction features\n",
    "df['tenure_x_monthly'] = df['tenure'] * df['MonthlyCharges']\n",
    "\n",
    "# Display the new features\n",
    "print(\"Dataset with new features:\")\n",
    "display(df.head())\n",
    "\n",
    "# Visualize some of the new features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='tenure_group', y='MonthlyCharges', hue='Churn', data=df)\n",
    "plt.title('Monthly Charges by Tenure Group and Churn Status')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='service_count', y='MonthlyCharges', hue='Churn', data=df)\n",
    "plt.title('Monthly Charges by Service Count and Churn Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection and Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare data for feature importance analysis\n",
    "# Convert categorical variables to numeric\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Binary encoding for Yes/No columns\n",
    "binary_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']\n",
    "for col in binary_cols:\n",
    "    df_encoded[col] = df_encoded[col].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# One-hot encoding for categorical columns\n",
    "cat_cols = ['gender', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
    "            'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
    "            'Contract', 'PaymentMethod', 'tenure_group']\n",
    "\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Prepare features and target\n",
    "X = df_encoded.drop('Churn', axis=1)\n",
    "y = df_encoded['Churn']\n",
    "\n",
    "# Train a Random Forest for feature importance\n",
    "rf_feat = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_feat.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_feat.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Display top 20 features\n",
    "print(\"Top 20 most important features:\")\n",
    "display(feature_importances.head(20))\n",
    "\n",
    "# Visualize feature importances\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importances.head(20))\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Select top features (you can adjust the threshold)\n",
    "top_features = feature_importances['feature'].head(25).tolist()\n",
    "X_selected = X[top_features]\n",
    "\n",
    "print(f\"Selected {len(top_features)} top features for modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Original training set shape: {np.bincount(y_train)}\")\n",
    "print(f\"Resampled training set shape: {np.bincount(y_train_smote)}\")\n",
    "\n",
    "# Define models to compare\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1])),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000),\n",
    "    'SVM': SVC(random_state=42, class_weight='balanced', probability=True)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': report['accuracy'],\n",
    "        'precision_churn': report['1']['precision'],\n",
    "        'recall_churn': report['1']['recall'],\n",
    "        'f1_churn': report['1']['f1-score'],\n",
    "        'report': classification_report(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"Accuracy: {report['accuracy']:.4f}\")\n",
    "    print(f\"Precision (Churn): {report['1']['precision']:.4f}\")\n",
    "    print(f\"Recall (Churn): {report['1']['recall']:.4f}\")\n",
    "    print(f\"F1 Score (Churn): {report['1']['f1-score']:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(results[name]['report'])\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Not Churn', 'Churn'],\n",
    "                yticklabels=['Not Churn', 'Churn'])\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve - {name}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot Precision-Recall curve\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "        pr_auc = average_precision_score(y_test, y_prob)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(recall, precision, lw=2, label=f'PR curve (area = {pr_auc:.2f})')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title(f'Precision-Recall Curve - {name}')\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Find the best performing model based on F1 score for churn class\n",
    "best_model_name = max(results, key=lambda x: results[x]['f1_churn'])\n",
    "print(f\"Best model based on F1 score for churn class: {best_model_name}\")\n",
    "\n",
    "# Define hyperparameter grid based on best model\n",
    "if best_model_name == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'class_weight': ['balanced', 'balanced_subsample']\n",
    "    }\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "    model = GradientBoostingClassifier(random_state=42)\n",
    "elif best_model_name == 'XGBoost':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'gamma': [0, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "        'scale_pos_weight': [1, 3, 5]\n",
    "    }\n",
    "    model = xgb.XGBClassifier(random_state=42)\n",
    "elif best_model_name == 'Logistic Regression':\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "        'class_weight': ['balanced', None]\n",
    "    }\n",
    "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "else:  # SVM\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.1, 0.01],\n",
    "        'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "        'class_weight': ['balanced', None]\n",
    "    }\n",
    "    model = SVC(random_state=42, probability=True)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "print(\"\\nPerforming hyperparameter tuning with GridSearchCV...\")\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit grid search to the data\n",
    "grid_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Get best parameters and model\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nBest Model Evaluation:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot confusion matrix for best model\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Not Churn', 'Churn'],\n",
    "            yticklabels=['Not Churn', 'Churn'])\n",
    "plt.title('Confusion Matrix - Best Model')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save the Best Model and Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a full preprocessing pipeline\n",
    "# This will include all the preprocessing steps we did manually\n",
    "\n",
    "# Save the column names for later use\n",
    "feature_columns = X_selected.columns.tolist()\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'improved_churn_model.pkl')\n",
    "joblib.dump(feature_columns, 'improved_churn_model_columns.pkl')\n",
    "joblib.dump(scaler, 'improved_churn_model_scaler.pkl')\n",
    "\n",
    "# Save the classification report\n",
    "with open('improved_classification_report.txt', 'w') as f:\n",
    "    f.write(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Model, feature columns, and scaler saved successfully!\")\n",
    "\n",
    "# Create a function to preprocess new data\n",
    "def preprocess_for_prediction(df_input):\n",
    "    \"\"\"\n",
    "    Preprocess a new customer dataframe for prediction.\n",
    "    \n",
    "    Args:\n",
    "        df_input: DataFrame with customer data\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed features ready for model prediction\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    \n",
    "    # Drop customerID if present\n",
    "    if 'customerID' in df.columns:\n",
    "        df = df.drop('customerID', axis=1)\n",
    "    \n",
    "    # Convert TotalCharges to numeric\n",
    "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "    df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
    "    \n",
    "    # Feature Engineering\n",
    "    # 1. Create tenure-related features\n",
    "    df['tenure_group'] = pd.qcut(df['tenure'], 4, labels=['0-1 year', '1-3 years', '3-5 years', '5+ years'])\n",
    "    \n",
    "    # 2. Create average monthly charge\n",
    "    df['avg_monthly_charges'] = df['TotalCharges'] / (df['tenure'] + 0.1)\n",
    "    \n",
    "    # 3. Create charge difference\n",
    "    df['charge_diff'] = df['MonthlyCharges'] - df['avg_monthly_charges']\n",
    "    \n",
    "    # 4. Create service count feature\n",
    "    service_columns = ['PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', \n",
    "                       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "    \n",
    "    df['service_count'] = df.apply(count_services, axis=1)\n",
    "    \n",
    "    # 5. Create binary flags for premium services\n",
    "    df['has_premium_tech'] = df['TechSupport'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "    df['has_premium_security'] = df['OnlineSecurity'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "    df['has_premium_support'] = df[['OnlineBackup', 'DeviceProtection']].apply(\n",
    "        lambda x: 1 if 'Yes' in x.values else 0, axis=1\n",
    "    )\n",
    "    df['has_streaming'] = df[['StreamingTV', 'StreamingMovies']].apply(\n",
    "        lambda x: 1 if 'Yes' in x.values else 0, axis=1\n",
    "    )\n",
    "    \n",
    "    # 6. Create interaction features\n",
    "    df['tenure_x_monthly'] = df['tenure'] * df['MonthlyCharges']\n",
    "    \n",
    "    # Binary encoding for Yes/No columns\n",
    "    binary_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']\n",
    "    for col in binary_cols:\n",
    "        df[col] = df[col].map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    # One-hot encoding for categorical columns\n",
    "    cat_cols = ['gender', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
    "                'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
    "                'Contract', 'PaymentMethod', 'tenure_group']\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "    \n",
    "    # Ensure all required columns are present\n",
    "    for col in feature_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    \n",
    "    # Select only the required columns in the correct order\n",
    "    df = df[feature_columns]\n",
    "    \n",
    "    # Scale the features\n",
    "    df_scaled = scaler.transform(df)\n",
    "    \n",
    "    return df_scaled\n",
    "\n",
    "# Save the preprocessing function\n",
    "joblib.dump(preprocess_for_prediction, 'improved_churn_preprocess.pkl')\n",
    "\n",
    "print(\"Preprocessing function saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a summary of model performance\n",
    "model_summary = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [results[model]['accuracy'] for model in results],\n",
    "    'Precision (Churn)': [results[model]['precision_churn'] for model in results],\n",
    "    'Recall (Churn)': [results[model]['recall_churn'] for model in results],\n",
    "    'F1 Score (Churn)': [results[model]['f1_churn'] for model in results]\n",
    "}).sort_values('F1 Score (Churn)', ascending=False)\n",
    "\n",
    "print(\"Model Performance Summary:\")\n",
    "display(model_summary)\n",
    "\n",
    "# Plot model comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "model_summary.set_index('Model').plot(kind='bar', figsize=(12, 8))\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare with original model\n",
    "print(\"\\nOriginal Model Performance:\")\n",
    "with open('classification_report.txt', 'r') as f:\n",
    "    original_report = f.read()\n",
    "print(original_report)\n",
    "\n",
    "print(\"\\nBest New Model Performance:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nImprovement Summary:\")\n",
    "print(\"1. Added feature engineering to create more predictive variables\")\n",
    "print(\"2. Addressed class imbalance using SMOTE\")\n",
    "print(\"3. Compared multiple algorithms to find the best performer\")\n",
    "print(\"4. Performed hyperparameter tuning to optimize model performance\")\n",
    "print(\"5. Created a comprehensive preprocessing pipeline for new data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}